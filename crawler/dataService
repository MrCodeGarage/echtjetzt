#!/usr/bin/env perl
use Mojolicious::Lite;
use Mojo::Base -signatures;
use Mojo::CSV;

our $VERSION = 0.01;

plugin 'Config' => {
  default => {
    pageFile => app->home->child('Data', 'Linkliste_KIvsVirus.csv')->to_string
  }
};

hook before_server_start => sub ($server, $app) {
  app->init_config;
};

helper init_config => sub ($c) {
  my $app = $c->app;
  # Create in-memory map of credible sources
  # based on the pages to crawl
  my $pages = $app->config('pages') // [];


  # In addition to the config file (maybe instead)
  # crawl the CSV file with pages to crawl
  if (my $page_file = $app->config('pageFile')) {
    my $data = Mojo::CSV->new->slurp_body($page_file);

    # Add each page to the config
    $data->each(
      sub {
        push @$pages, {
          url => $_->[1],
          cred => $_->[3],
          freq => ''
        };
      }
    );
  };

  my $credible = $app->config('credible') // {};
  foreach (@$pages) {
    my $source = Mojo::URL->new($_->{url})->host;

    # Always take the lowest credibility value,
    # if already set - otherwise set
    if (!exists($credible->{$source})
          || $credible->{$source} > $_->{cred}) {
      $credible->{$source} = $_->{cred};
    }
  };

  # Reset list of credible sources
  $app->config(credible => $credible);
};


# Register crawl command
push @{app->commands->namespaces}, 'DataService';


# Get the credibility score of a source
helper 'get_credibility' => sub ($c, $url) {
  my $source = Mojo::URL->new($url)->host;
  return $c->config('credible')->{$source} // 0.0;
};


# Fetch resource blocking (temporarily)
helper 'fetch' => sub ($c, $url) {

  # Fetch the resource blocking (why not?)
  my $tx = $c->ua->get($url);
  my $res = $tx->result;

  if ($res->is_success) {
    return {
      headers => $res->headers->to_hash,
      body => $res->body,
      url => $url
    };
  }

  # An error occurred
  elsif ($res->is_error) {
    return {
      error => $res->message,
      url => $url
    }
  };

  return {
    error => 'Unknown error',
    url => $url
  };
};


# Clean resource with default cleaners
helper 'clean' => sub ($c, $cascade, $res) {

  # Initialize cleaned data
  my $data = {
    header => $res->{headers},
    html => $res->{body},
    metadata => {},
    links => []
  };

  # Iterate over all cleaners
  foreach (@$cascade) {

    # Call the cleaner as
    # cleaner(
    #   header => $header,
    #   metadata => {},
    #   html => $html,
    #   links => []
    # )
    $data = $_->(%$data)
  };

  return $data;
};


# Return the credibility score of a source
get '/credibility' => sub ($c) {
  # TODO:
  #   Validate input
  my $url = $c->param('url');
  $c->render(json => {
    url => $url,
    score => $c->get_credibility($url)
  });
};


# Return the clean data of a url
get '/clean' => sub ($c) {
  # TODO:
  #   Validate input
  # TODO:
  #   Ensure this is an absolue URL
  my $url = $c->param('url');

  my $res = $c->fetch($url);

  # An error occurred
  if ($res->{error}) {
    return $c->render(json => $res)
  };

  return $c->render(
    # TODO:
    #   use base cleaner cascade
    json => $c->clean([sub { return $_[0] } ], $res)
  );
};


# Add a new base doc to the list
post '/add' => sub ($c) {

  # TODO:
  #   Validate input
  my $baseurl = $c->param('baseurl');
  my $cred = $c->param('cred');
  my $freq = $c->param('freq');

  # Yada yada
  ...
};

app->start;
